{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_num=9\n",
    "cuda_num = str(3)\n",
    "date='12.01'\n",
    "trainingSet_path0= \"../data/sentiment/quan_9/train_\"+date+\".txt\"\n",
    "valSet_path0= \"../data/sentiment/quan_9/test_\"+date+\".txt\"\n",
    "zeng_path0= \"../data/sentiment/quan_9/zeng.txt\"\n",
    "model_save_path='../result/classifier_'+date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "手动实现transformer.models.bert.BertForSequenceClassification()函数\n",
    "根据论文[How to Fine-Tune BERT for Text Classification（2019）](https://www.aclweb.org/anthology/P18-1031.pdf)\n",
    "在分类问题上，把最后四层进行concat然后maxpooling 输出的结果会比直接输出最后一层的要好\n",
    "这里进行实现测试\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel,BertTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class bert_lr_last4layer_Config(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.bert_path = \"../chinese-bert-wwm\"\n",
    "        self.config_path = \"../chinese-bert-wwm/config.json\"\n",
    "\n",
    "        # self.tokenizer = BertTokenizer.from_pretrained(self.bert_path)\n",
    "        self.hidden_size = 768\n",
    "        self.num_labels = type_num\n",
    "        # self.dropout_bertout = 0.2\n",
    "        self.dropout_bertout = 0.5\n",
    "        self.mytrainedmodel = \"../result/bert_clf_model.bin\"\n",
    "        \"\"\"\n",
    "        current loss: 0.4363991916179657 \t current acc: 0.8125\n",
    "        current loss: 0.1328232882924341 \t current acc: 0.9527363184079602\n",
    "        current loss: 0.11797185830000853 \t current acc: 0.9585411471321695\n",
    "        train loss:  0.11880445411248554 \t train acc: 0.9583704495516361\n",
    "        valid loss:  0.1511497257672476 \t valid acc: 0.9431549028896258\n",
    "        \"\"\"\n",
    "\n",
    "class bert_lr_last4layer(nn.Module):\n",
    "\n",
    "    def __init__(self,config):\n",
    "        super(bert_lr_last4layer, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(config.bert_path,config = config.config_path)\n",
    "        self.dropout_bertout = nn.Dropout(config.dropout_bertout)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=True,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        # outputs = outputs[2] # [1]是pooled的结果 # [3]是hidden_states 12层\n",
    "        hidden_states = outputs.hidden_states\n",
    "        nopooled_output = torch.cat((hidden_states[9],hidden_states[10],hidden_states[11],hidden_states[12]),1)\n",
    "        batch_size = nopooled_output.shape[0] # 32\n",
    "        # print(batch_size)\n",
    "        # print(nopooled_output.shape) # torch.Size([32, 400, 768])\n",
    "        kernel_hight = nopooled_output.shape[1]\n",
    "        pooled_output = F.max_pool2d(nopooled_output,kernel_size = (kernel_hight,1))\n",
    "        # print(pooled_output.shape) # torch.Size([32, 1, 768])\n",
    "\n",
    "        flatten = pooled_output.view(batch_size,-1)\n",
    "        # print(flatten.shape) # [32,768]\n",
    "\n",
    "        flattened_output = self.dropout_bertout(flatten)\n",
    "\n",
    "        logits = self.classifier(flattened_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return loss,logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.config_dict = {\n",
    "            \"data_path\": {\n",
    "                # \"trainingSet_path\": \"../data/sentiment/sentiment.train0.data\",\n",
    "                # \"valSet_path\": \"../data/sentiment/sentiment.valid0.data\",\n",
    "                \"trainingSet_path\": trainingSet_path0,\n",
    "                \"valSet_path\": valSet_path0,\n",
    "                \"testingSet_path\": \"../data/sentiment/sentiment.test0.data\",\n",
    "                \"zeng_path\": zeng_path0\n",
    "            },\n",
    "\n",
    "            \"BERT_path\": {\n",
    "                \"file_path\": '../chinese-bert-wwm/',\n",
    "                \"config_path\": '../chinese-bert-wwm/',\n",
    "                \"vocab_path\": '../chinese-bert-wwm/',\n",
    "            },\n",
    "\n",
    "            \"training_rule\": {\n",
    "                \"max_length\": 300,  # 输入序列长度，别超过512\n",
    "                \"hidden_dropout_prob\": 0.3,\n",
    "                \"num_labels\": type_num,  # 几分类个数\n",
    "                \"learning_rate\": 1e-5,\n",
    "                \"weight_decay\": 1e-2,\n",
    "                \"batch_size\": 16\n",
    "            },\n",
    "\n",
    "            \"result\": {\n",
    "                \"model_save_path\": '../result/bert_clf_model.bin',\n",
    "                \"config_save_path\": '../result/bert_clf_config.json',\n",
    "                \"vocab_save_path\": '../result/bert_clf_vocab.txt'\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def get(self, section, name):\n",
    "        return self.config_dict[section][name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, path_to_file):\n",
    "#         print(path_to_file)\n",
    "        self.dataset = pd.read_csv(path_to_file, sep=\"\\t\", names=[\"text\", \"label\"])\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset.loc[idx, \"text\"]\n",
    "        label = self.dataset.loc[idx, \"label\"]\n",
    "        sample = {\"text\": text, \"label\": label}\n",
    "        # print(sample)\n",
    "        return sample\n",
    "\n",
    "def convert_text_to_ids(tokenizer, text, max_len=100):\n",
    "    if isinstance(text, str):\n",
    "        tokenized_text = tokenizer.encode_plus(text, max_length=max_len, add_special_tokens=True, truncation=True)\n",
    "        input_ids = tokenized_text[\"input_ids\"]\n",
    "        token_type_ids = tokenized_text[\"token_type_ids\"]\n",
    "    elif isinstance(text, list):\n",
    "        input_ids = []\n",
    "        token_type_ids = []\n",
    "        for t in text:\n",
    "            tokenized_text = tokenizer.encode_plus(t, max_length=max_len, add_special_tokens=True, truncation=True)\n",
    "            input_ids.append(tokenized_text[\"input_ids\"])\n",
    "            token_type_ids.append(tokenized_text[\"token_type_ids\"])\n",
    "    else:\n",
    "        print(\"Unexpected input\")\n",
    "    return input_ids, token_type_ids\n",
    "\n",
    "def seq_padding(tokenizer, X):\n",
    "    pad_id = tokenizer.convert_tokens_to_ids(\"[PAD]\")\n",
    "    if len(X) <= 1:\n",
    "        return torch.tensor(X)\n",
    "    L = [len(x) for x in X]\n",
    "    ML = max(L)\n",
    "    X = torch.Tensor([x + [pad_id] * (ML - len(x)) if len(x) < ML else x for x in X])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import numpy\n",
    "import transformers\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformers_bert_binary_classification(object):\n",
    "    def __init__(self):\n",
    "        self.config = Config()\n",
    "        self.device_setup()\n",
    "\n",
    "    def device_setup(self):\n",
    "        \"\"\"\n",
    "        设备配置并加载BERT模型\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.freezeSeed()\n",
    "        # 使用GPU，通过model.to(device)的方式使用\n",
    "        device_s = \"cuda:\" + cuda_num\n",
    "        self.device = torch.device(device_s if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # import os\n",
    "        # result_dir = \"../result\"\n",
    "        # MODEL_PATH = self.config.get(\"BERT_path\", \"file_path\")\n",
    "        # config_PATH = self.config.get(\"BERT_path\", \"config_path\")\n",
    "        vocab_PATH = self.config.get(\"BERT_path\", \"vocab_path\")\n",
    "\n",
    "        # num_labels = self.config.get(\"training_rule\", \"num_labels\")\n",
    "        # hidden_dropout_prob = self.config.get(\"training_rule\", \"hidden_dropout_prob\")\n",
    "\n",
    "        # 通过词典导入分词器\n",
    "        self.tokenizer = transformers.BertTokenizer.from_pretrained(vocab_PATH)\n",
    "        # self.model_config = BertConfig.from_pretrained(config_PATH, num_labels=num_labels,\n",
    "        #                                                hidden_dropout_prob=hidden_dropout_prob)\n",
    "        # self.model = BertForSequenceClassification.from_pretrained(MODEL_PATH, config=self.model_config)\n",
    "        \"\"\"\n",
    "        train loss:  0.10704718510208534 \t train acc: 0.9637151849872321\n",
    "        valid loss:  0.17820182011222863 \t valid acc: 0.9459971577451445\n",
    "        \"\"\"\n",
    "        # 如果想换模型，换成下边这句子\n",
    "        # bert+lr 跟官方方法差不都\n",
    "        # self.model = bert_lr(bert_lr_Config())\n",
    "        # self.model = bert_cnn(bert_cnn_Config())\n",
    "        self.model = bert_lr_last4layer(bert_lr_last4layer_Config())\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def model_setup(self, zeng=0):\n",
    "        weight_decay = self.config.get(\"training_rule\", \"weight_decay\")\n",
    "        learning_rate = self.config.get(\"training_rule\", \"learning_rate\")\n",
    "        print(\"**model_setup:\")\n",
    "        print(\"zeng\",zeng)\n",
    "        if zeng == 1:\n",
    "            learning_rate = learning_rate * 2\n",
    "        # 定义优化器和损失函数\n",
    "        # Prepare optimizer and schedule (linear warmup and decay)\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.0}\n",
    "        ]\n",
    "        self.optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(np.array([3.0,2.0,5.0,10.0,7.0,2.3,10.0,10.0,10.0])).float())\n",
    "        self.criterion.to(self.device)\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        读取数据\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        train_set_path = self.config.get(\"data_path\", \"trainingSet_path\")\n",
    "        valid_set_path = self.config.get(\"data_path\", \"valSet_path\")\n",
    "        batch_size = self.config.get(\"training_rule\", \"batch_size\")\n",
    "        zeng_set_path = self.config.get(\"data_path\", \"zeng_path\")\n",
    "        print(train_set_path,valid_set_path,batch_size,zeng_set_path)\n",
    "\n",
    "        # 数据读入\n",
    "        # 加载数据集\n",
    "        sentiment_train_set = SentimentDataset(train_set_path)\n",
    "        sentiment_train_loader = DataLoader(sentiment_train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        sentiment_valid_set = SentimentDataset(valid_set_path)\n",
    "        sentiment_valid_loader = DataLoader(sentiment_valid_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "        sentiment_zeng_set = SentimentDataset(zeng_set_path)\n",
    "        sentiment_zeng_loader = DataLoader(sentiment_zeng_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "        return sentiment_train_loader, sentiment_valid_loader, sentiment_zeng_loader\n",
    "\n",
    "    def train_an_epoch(self, iterator, zeng=0):\n",
    "        print(\"**train_an_epoch\")\n",
    "        print(\"zeng\",zeng)\n",
    "        self.model_setup(zeng)\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "\n",
    "        for i, batch in enumerate(iterator):\n",
    "            label = batch[\"label\"]\n",
    "            text = batch[\"text\"]\n",
    "            # print(label)\n",
    "            input_ids, token_type_ids = convert_text_to_ids(self.tokenizer, text)\n",
    "            input_ids = seq_padding(self.tokenizer, input_ids)\n",
    "            token_type_ids = seq_padding(self.tokenizer, token_type_ids)\n",
    "            # 标签形状为 (batch_size, 1)\n",
    "            label = label.unsqueeze(1)\n",
    "            # 需要 LongTensor\n",
    "            input_ids, token_type_ids, label = input_ids.long(), token_type_ids.long(), label.long()\n",
    "            # 梯度清零\n",
    "            self.optimizer.zero_grad()\n",
    "            # 迁移到GPU\n",
    "            input_ids, token_type_ids, label = input_ids.to(self.device), token_type_ids.to(self.device), label.to(\n",
    "                self.device)\n",
    "            output = self.model(input_ids=input_ids, token_type_ids=token_type_ids, labels=label)  # 这里不需要labels\n",
    "            # BertForSequenceClassification的输出loss和logits\n",
    "            # BertModel原本的模型输出是last_hidden_state，pooler_output\n",
    "            # bert_cnn的输出是[batch_size, num_class]\n",
    "            # print(numpy.array(torch.tensor(output).cpu()).shape)\n",
    "\n",
    "            y_pred_prob = output[1]\n",
    "            y_pred_label = y_pred_prob.argmax(dim=1)\n",
    "\n",
    "            # 计算loss\n",
    "            # 这个 loss 和 output[0] 是一样的\n",
    "            loss = self.criterion(y_pred_prob.view(-1, type_num), label.view(-1))  # 多分类改这里\n",
    "            # loss = output[0]\n",
    "            # 计算acc\n",
    "            acc = ((y_pred_label == label.view(-1)).sum()).item()\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            # epoch 中的 loss 和 acc 累加\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "            if i % 200 == 0:\n",
    "                print(\"current loss:\", epoch_loss / (i + 1), \"\\t\", \"current acc:\", epoch_acc / ((i + 1) * len(label)))\n",
    "        return epoch_loss / len(iterator), epoch_acc / len(iterator.dataset.dataset)\n",
    "\n",
    "    def evaluate(self, iterator):\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        y_pred_label_all = []\n",
    "        label_all = []\n",
    "        with torch.no_grad():\n",
    "            for _, batch in enumerate(iterator):\n",
    "                label = batch[\"label\"]\n",
    "                text = batch[\"text\"]\n",
    "\n",
    "                input_ids, token_type_ids = convert_text_to_ids(self.tokenizer, text)\n",
    "                input_ids = seq_padding(self.tokenizer, input_ids)\n",
    "                token_type_ids = seq_padding(self.tokenizer, token_type_ids)\n",
    "                label = label.unsqueeze(1)\n",
    "                input_ids, token_type_ids, label = input_ids.long(), token_type_ids.long(), label.long()\n",
    "                input_ids, token_type_ids, label = input_ids.to(self.device), token_type_ids.to(self.device), label.to(\n",
    "                    self.device)\n",
    "                output = self.model(input_ids=input_ids, token_type_ids=token_type_ids, labels=label)\n",
    "                # 更改了以下部分\n",
    "                # y_pred_label = output[1].argmax(dim=1)\n",
    "                y_pred_prob = output[1]\n",
    "                y_pred_label = y_pred_prob.argmax(dim=1)\n",
    "                loss = output[0]\n",
    "                # loss = self.criterion(y_pred_prob.view(-1, 2), label.view(-1))\n",
    "                acc = ((y_pred_label == label.view(-1)).sum()).item()\n",
    "                y_pred_label_all += y_pred_label.tolist()\n",
    "                label_all += label.view(-1).tolist()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_acc += acc\n",
    "\n",
    "        print(metrics.classification_report(y_pred_label_all, label_all))\n",
    "        print(\"准确率:\", metrics.accuracy_score(y_pred_label_all, label_all))\n",
    "        return epoch_loss / len(iterator), epoch_acc / len(iterator.dataset.dataset)\n",
    "\n",
    "    def train(self, epochs, zeng=0):\n",
    "        sentiment_train_loader, sentiment_valid_loader, sentiment_zeng_loader = self.get_data()\n",
    "\n",
    "        for i in range(epochs):\n",
    "            print('____________________________________________________________________________________')\n",
    "            print('____________________________________________________________________________________')\n",
    "            print('epochs:', i)\n",
    "            print('____________________________________________________________________________________')\n",
    "            print('____________________________________________________________________________________')\n",
    "            print('____train____')\n",
    "            if zeng == 0:\n",
    "                train_loss, train_acc = self.train_an_epoch(sentiment_train_loader)\n",
    "            else:\n",
    "                train_loss, train_acc = self.train_an_epoch(sentiment_zeng_loader, 1)\n",
    "            print(\"train loss: \", train_loss, \"\\t\", \"train acc:\", train_acc)\n",
    "            print('____evaluate____')\n",
    "            valid_loss, valid_acc = self.evaluate(sentiment_valid_loader)\n",
    "            print(\"valid loss: \", valid_loss, \"\\t\", \"valid acc:\", valid_acc)\n",
    "        # self.save_model()\n",
    "\n",
    "    def save_model(self):\n",
    "        model_save_path = self.config.get(\"result\", \"model_save_path\")\n",
    "        config_save_path = self.config.get(\"result\", \"config_save_path\")\n",
    "        vocab_save_path = self.config.get(\"result\", \"vocab_save_path\")\n",
    "\n",
    "        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model\n",
    "        torch.save(model_to_save.state_dict(), model_save_path)\n",
    "        # model_to_save.config.to_json_file(config_save_path) # !!!'bert_lr' object has no attribute 'config'\n",
    "        # self.tokenizer.save_vocabulary(vocab_save_path)\n",
    "        print(\"model saved...\")\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        # self.model.setup()\n",
    "        self.model_setup()\n",
    "        self.model.eval()\n",
    "        # 转token后padding\n",
    "        input_ids, token_type_ids = convert_text_to_ids(self.tokenizer, sentence)\n",
    "        input_ids = seq_padding(self.tokenizer, [input_ids])\n",
    "        token_type_ids = seq_padding(self.tokenizer, [token_type_ids])\n",
    "        # 需要 LongTensor\n",
    "        input_ids, token_type_ids = input_ids.long(), token_type_ids.long()\n",
    "        # 梯度清零\n",
    "        self.optimizer.zero_grad()\n",
    "        # 迁移到GPU\n",
    "        input_ids, token_type_ids = input_ids.to(self.device), token_type_ids.to(self.device)\n",
    "        output = self.model(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "        # y_pred_prob:各个类别的概率\n",
    "        y_pred_prob = output[0]\n",
    "        # 取概率最大的标签\n",
    "        y_pred_label = y_pred_prob.argmax(dim=1)\n",
    "\n",
    "        # 将torch.tensor转换回int形式\n",
    "        return y_pred_prob, y_pred_label.item()\n",
    "\n",
    "    def freezeSeed(self):\n",
    "        seed = 1\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)  # Numpy module.\n",
    "        random.seed(seed)  # Python random module.\n",
    "        torch.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/sentiment/quan_9/train_10.14.txt ../data/sentiment/quan_9/test_10.14.txt 16 ../data/sentiment/quan_9/zeng.txt\n",
      "____________________________________________________________________________________\n",
      "____________________________________________________________________________________\n",
      "epochs: 0\n",
      "____________________________________________________________________________________\n",
      "____________________________________________________________________________________\n",
      "____train____\n",
      "**train_an_epoch\n",
      "zeng 0\n",
      "**model_setup:\n",
      "zeng 0\n",
      "current loss: 3.0272715091705322 \t current acc: 0.0625\n",
      "current loss: 1.6890660757152596 \t current acc: 0.5093283582089553\n",
      "train loss:  1.1610668734435101 \t train acc: 0.6727059218251971\n",
      "____evaluate____\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81       359\n",
      "           1       0.93      0.90      0.91      1089\n",
      "           2       0.99      0.96      0.98       264\n",
      "           3       0.88      0.63      0.73       143\n",
      "           4       0.99      0.95      0.97       149\n",
      "           5       0.80      0.95      0.87       405\n",
      "           6       0.62      0.67      0.65        60\n",
      "           7       0.95      0.88      0.92        86\n",
      "           8       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      2555\n",
      "   macro avg       0.78      0.75      0.76      2555\n",
      "weighted avg       0.89      0.88      0.88      2555\n",
      "\n",
      "准确率: 0.8790606653620352\n",
      "valid loss:  0.3905700073577464 \t valid acc: 0.8790606653620352\n",
      "____________________________________________________________________________________\n",
      "____________________________________________________________________________________\n",
      "epochs: 1\n",
      "____________________________________________________________________________________\n",
      "____________________________________________________________________________________\n",
      "____train____\n",
      "**train_an_epoch\n",
      "zeng 0\n",
      "**model_setup:\n",
      "zeng 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/fuwen/anaconda3/envs/sw0/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/fuwen/anaconda3/envs/sw0/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/fuwen/anaconda3/envs/sw0/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current loss: 0.9613236784934998 \t current acc: 0.8125\n",
      "current loss: 0.3720014309927599 \t current acc: 0.8970771144278606\n",
      "train loss:  0.3444768136252347 \t train acc: 0.9013588324106694\n",
      "____evaluate____\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83       356\n",
      "           1       0.93      0.93      0.93      1050\n",
      "           2       0.98      0.96      0.97       263\n",
      "           3       0.88      0.93      0.90        97\n",
      "           4       0.97      0.99      0.98       140\n",
      "           5       0.87      0.95      0.91       439\n",
      "           6       0.73      0.44      0.55       106\n",
      "           7       0.94      0.91      0.93        82\n",
      "           8       0.21      0.27      0.24        22\n",
      "\n",
      "    accuracy                           0.90      2555\n",
      "   macro avg       0.82      0.80      0.81      2555\n",
      "weighted avg       0.90      0.90      0.90      2555\n",
      "\n",
      "准确率: 0.900587084148728\n",
      "valid loss:  0.31050597212743014 \t valid acc: 0.900587084148728\n",
      "____________________________________________________________________________________\n",
      "____________________________________________________________________________________\n",
      "epochs: 2\n",
      "____________________________________________________________________________________\n",
      "____________________________________________________________________________________\n",
      "____train____\n",
      "**train_an_epoch\n",
      "zeng 0\n",
      "**model_setup:\n",
      "zeng 0\n",
      "current loss: 0.4107864201068878 \t current acc: 0.875\n",
      "current loss: 0.19433059846861891 \t current acc: 0.9424751243781094\n",
      "train loss:  0.19762322136847646 \t train acc: 0.9426270759939608\n",
      "____evaluate____\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       312\n",
      "           1       0.93      0.94      0.93      1045\n",
      "           2       0.99      0.97      0.98       262\n",
      "           3       0.91      0.78      0.84       119\n",
      "           4       0.98      0.98      0.98       142\n",
      "           5       0.86      0.95      0.90       430\n",
      "           6       0.70      0.48      0.57        94\n",
      "           7       0.95      0.90      0.93        84\n",
      "           8       0.61      0.25      0.36        67\n",
      "\n",
      "    accuracy                           0.90      2555\n",
      "   macro avg       0.86      0.80      0.82      2555\n",
      "weighted avg       0.89      0.90      0.89      2555\n",
      "\n",
      "准确率: 0.899412915851272\n",
      "valid loss:  0.323218053788878 \t valid acc: 0.899412915851272\n",
      "____________________________________________________________________________________\n",
      "____________________________________________________________________________________\n",
      "epochs: 3\n",
      "____________________________________________________________________________________\n",
      "____________________________________________________________________________________\n",
      "____train____\n",
      "**train_an_epoch\n",
      "zeng 0\n",
      "**model_setup:\n",
      "zeng 0\n",
      "current loss: 0.08620473742485046 \t current acc: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38859/3602842389.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformers_bert_binary_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzeng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model saving...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model saved\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_38859/756440163.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, zeng)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'____train____'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mzeng\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_an_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_an_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_zeng_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_38859/756440163.py\u001b[0m in \u001b[0;36mtrain_an_epoch\u001b[0;34m(self, iterator, zeng)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;31m# 反向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0;31m# epoch 中的 loss 和 acc 累加\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/sw0/lib/python3.7/site-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"correct_bias\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# No bias correction for Bert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                     \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0mbias_correction2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = transformers_bert_binary_classification()\n",
    "classifier.train(5,zeng=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saving...\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "print(\"model saving...\")\n",
    "torch.save(classifier, model_save_path)\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**model_setup:\n",
      "zeng 0\n",
      "e络盟社区发布新一期3D打印电子书 \n",
      " 1 新能源汽车 3.611053466796875 \n",
      " [2.6574759483337402, 3.611053466796875, -2.8559532165527344, -0.9616577625274658, -3.006239891052246, 0.1720058023929596, 1.386844515800476, -2.780341148376465, -0.01032891683280468] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "2021中国国际消费电子博览会和青岛国际软件融合创新博览会开幕 \n",
      " 1 新能源汽车 4.102621555328369 \n",
      " [1.287731409072876, 4.102621555328369, -3.260075569152832, -1.2382889986038208, -2.966135025024414, 0.6029578447341919, 0.6527237296104431, -2.318208932876587, 0.8133870363235474] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "4D打印软体机器人：打印出来即可工作 \n",
      " 6 工业机器人 6.2176995277404785 \n",
      " [1.063570261001587, 0.4892582595348358, -1.6062324047088623, -1.1194864511489868, -2.148484230041504, -1.1868513822555542, 6.2176995277404785, -2.3463759422302246, 0.5314106345176697] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "2021中国国际消费电子博览会和青岛国际软件融合创新博览会盛大开幕 \n",
      " 1 新能源汽车 3.9393742084503174 \n",
      " [1.3462393283843994, 3.9393742084503174, -3.367501735687256, -1.292984962463379, -3.013441562652588, 0.8227241039276123, 0.8283470869064331, -2.455658435821533, 0.9345062971115112] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "这个被国外指南淘汰十几年的手术 终于被踢出中国专家共识 \n",
      " 3 医疗器械 4.661919116973877 \n",
      " [0.5968437194824219, -0.7538324594497681, -1.1529395580291748, 4.661919116973877, -1.4759562015533447, -0.7887404561042786, -0.647005021572113, -1.5130493640899658, 0.761654257774353] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "国家药监局最新发布！体外诊断试剂临床试验技术指导原则 \n",
      " 3 医疗器械 6.744363784790039 \n",
      " [0.050858497619628906, -1.308514952659607, 1.7484266757965088, 6.744363784790039, -1.0692083835601807, -1.5398627519607544, -0.6963271498680115, -1.2446805238723755, -0.5541353821754456] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "院士联合实验室广州成立 加速大湾区医疗科研成果临床转化 \n",
      " 3 医疗器械 6.318398952484131 \n",
      " [0.23370301723480225, -1.310604453086853, -0.030122756958007812, 6.318398952484131, -1.31698739528656, -1.265159010887146, -0.26906073093414307, -1.0382778644561768, -0.3706330955028534] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "巨头入局、资本追捧！疫情催生下数字疗法成“医疗新风口” \n",
      " 3 ***** 其他 ***** 原预测: 医疗器械 2.954923629760742 \n",
      " [1.3017873764038086, -1.392510175704956, 1.2721359729766846, 2.954923629760742, -1.9381678104400635, -0.3353213667869568, 0.7125450968742371, -2.2628698348999023, 0.4665547311306] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "国家药监局发布新体外诊断试剂临床试验技术指导原则 \n",
      " 3 医疗器械 6.22953462600708 \n",
      " [-0.16575351357460022, -1.193779706954956, 2.590034008026123, 6.22953462600708, -1.1428650617599487, -1.7695056200027466, -0.8047032952308655, -1.2960127592086792, -0.6578003168106079] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "康复医疗行业：医院、医生等促进康复医疗服务持续扩大 \n",
      " 3 医疗器械 6.462620258331299 \n",
      " [0.8627249002456665, -0.9362145066261292, -1.0166015625, 6.462620258331299, -1.3191684484481812, -1.5517786741256714, -0.17311449348926544, -1.9010000228881836, 0.08652052283287048] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "亿航智能自动驾驶飞行器 VT-30 首次公开亮相：航程 300 公里 \n",
      " 1 新能源汽车 4.72117280960083 \n",
      " [1.4529633522033691, 4.72117280960083, -2.3402230739593506, -1.087225317955017, -2.899007797241211, -0.28293582797050476, 1.3217452764511108, -1.9944813251495361, -0.29560962319374084] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "亿航智能自动驾驶飞行器VT-30首次公开亮相：航程300公里 \n",
      " 1 新能源汽车 4.72117280960083 \n",
      " [1.4529633522033691, 4.72117280960083, -2.3402230739593506, -1.087225317955017, -2.899007797241211, -0.28293582797050476, 1.3217452764511108, -1.9944813251495361, -0.29560962319374084] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "美股周一：特斯拉上涨2.2%阿里上涨3.5% \n",
      " 1 新能源汽车 6.170680522918701 \n",
      " [2.2091898918151855, 6.170680522918701, -2.378488540649414, -1.3107304573059082, -1.9398633241653442, 0.6390150189399719, -0.9386850595474243, -2.0532453060150146, -1.2607433795928955] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "苹果原设计大师艾维与法拉利合作，或与电动车相 \n",
      " 1 新能源汽车 6.35860538482666 \n",
      " [2.4741315841674805, 6.35860538482666, -2.350477457046509, -0.9383748173713684, -2.398165225982666, 0.06121239811182022, -0.9012936949729919, -1.9860605001449585, -1.0904667377471924] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "北京：9月28日起禁止乘客携带电动代步工具乘地铁 \n",
      " 1 新能源汽车 3.727969169616699 \n",
      " [0.08035477995872498, 3.727969169616699, -1.8056282997131348, -1.3025927543640137, -1.601577639579773, -1.0969700813293457, -1.9279935359954834, 2.746983289718628, -0.482018381357193] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "吉利子公司要搞飞行汽车，未来 3 到 5 年落地中国 \n",
      " 1 新能源汽车 6.127352237701416 \n",
      " [2.8622570037841797, 6.127352237701416, -2.1613705158233643, -1.317680835723877, -2.3299636840820312, -0.2574162185192108, -0.5711799263954163, -2.1360344886779785, -0.9576953649520874] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "高交会引领创新科技高质量发展，让新时代、新技术、新经济澎湃新未来 \n",
      " 6 ***** 其他 ***** 原预测: 工业机器人 2.4394118785858154 \n",
      " [-0.27474021911621094, 1.9330300092697144, -2.573777437210083, -1.5354106426239014, -1.0414904356002808, 1.5122349262237549, 2.4394118785858154, -1.7646799087524414, 1.4858425855636597] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "一数科技入选庆祝建党100周年新能源成果展 \n",
      " 5 能源 4.580583572387695 \n",
      " [0.5882421135902405, 3.2742762565612793, -2.6808271408081055, -1.7977638244628906, -1.5414345264434814, 4.580583572387695, -0.09861810505390167, -2.615211009979248, -0.5445226430892944] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "国电建成全球最大新能源云平台，装机容量高达4.8亿千瓦 \n",
      " 5 能源 6.688464641571045 \n",
      " [0.6099869012832642, 1.152754783630371, -2.003948450088501, -2.196898937225342, -0.6270169019699097, 6.688464641571045, -0.6860017776489258, -2.600051164627075, -1.1368680000305176] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "《2021全球新能源企业500强分析报告》发布 \n",
      " 5 能源 5.793091773986816 \n",
      " [0.22204765677452087, 2.3313097953796387, -2.353586196899414, -1.9510421752929688, -0.8217506408691406, 5.793091773986816, -0.6646420359611511, -2.1146748065948486, -1.424757480621338] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "中联农机摆擂台，安徽农机驾驶高手技能大比武 \n",
      " 1 新能源汽车 4.644991397857666 \n",
      " [0.748310387134552, 4.644991397857666, -3.1226933002471924, -0.6811395287513733, -2.697629451751709, 0.1548890769481659, 0.4610421359539032, -1.9060490131378174, 0.9331052899360657] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "中国商飞：6架C919国产大飞机正试验试飞，CR929研制进展顺利 \n",
      " 1 ***** 其他 ***** 原预测: 新能源汽车 3.348958969116211 \n",
      " [1.499985694885254, 3.348958969116211, -2.5067543983459473, -1.339670181274414, -2.6292877197265625, -0.47689089179039, 0.11896410584449768, 0.08030983060598373, 0.5593671202659607] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "库克被曝曾斥资1010万美元在加州购买豪宅面积 \n",
      " 0 ICT 4.508384704589844 \n",
      " [4.508384704589844, 1.895971655845642, -2.5413761138916016, -0.5570191740989685, -1.4210923910140991, -0.43906018137931824, 0.2701892852783203, -2.463419198989868, 0.6433796286582947] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "京东联手东营打造“四新”新引擎，推动经济高质量发展 \n",
      " 0 ICT 4.020406723022461 \n",
      " [4.020406723022461, 2.6709535121917725, -3.365694999694824, -1.6613229513168335, -2.534024715423584, 0.952770471572876, 1.0296721458435059, -2.766181230545044, 0.6485052704811096] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "机器人“带路”诊断，让肺结节不再成为“心结”！胸科医院取得呼吸介入临床研究新进展 \n",
      " 6 工业机器人 5.732199192047119 \n",
      " [0.983063280582428, -0.15023770928382874, -1.6759819984436035, -0.013626819476485252, -2.077421188354492, -1.0798962116241455, 5.732199192047119, -2.343299150466919, 0.30070972442626953] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "山西“产学研用”强强联手 释放煤机产业集群效应 \n",
      " 8 ***** 其他 ***** 原预测: 其他 3.0167174339294434 \n",
      " [-0.6803955435752869, 1.762473225593567, -2.8832836151123047, -1.374094009399414, -0.34702926874160767, 2.4446866512298584, 0.11837275326251984, -1.8697779178619385, 3.0167174339294434] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "重磅！传动系统巨头力纳克（LINAK）再有新动作 \n",
      " 1 新能源汽车 3.589541435241699 \n",
      " [0.3223836123943329, 3.589541435241699, -3.067063331604004, -0.5320013165473938, -2.0885372161865234, 1.7534493207931519, -0.03865816816687584, -1.9632660150527954, 0.7172231674194336] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "『宁夏』回族自治区综合交通运输体系“十四五”发展规划的通知 \n",
      " 7 先进轨道交通 5.56497859954834 \n",
      " [-0.8582262396812439, 1.86940598487854, -1.510716199874878, -0.8793053030967712, -1.1188938617706299, -0.6233862638473511, -1.7084964513778687, 5.56497859954834, -0.09708237648010254] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "『绵遂内铁路』可研工作正式启动 有望在2022年开工 \n",
      " 7 先进轨道交通 6.892961025238037 \n",
      " [-0.5766943693161011, 0.6538389921188354, -0.7071647644042969, -1.5080822706222534, -1.1709744930267334, -1.1653486490249634, -2.22524356842041, 6.892961025238037, -0.38092318177223206] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "『江苏』“十四五”铁路发展暨中长期路网布局规划的通知 \n",
      " 7 先进轨道交通 7.059116363525391 \n",
      " [-0.7438446283340454, 0.02344238944351673, -0.9235804677009583, -1.4464715719223022, -1.117512583732605, -0.9651454091072083, -2.239842414855957, 7.059116363525391, -0.39640775322914124] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "『杭台高铁』开启热滑试验 将于今年底通车 \n",
      " 7 先进轨道交通 6.552260398864746 \n",
      " [-0.39058148860931396, 1.0115240812301636, -0.9801320433616638, -1.7332911491394043, -1.462823748588562, -1.2374050617218018, -2.2425875663757324, 6.552260398864746, -0.4646010398864746] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "产业巨头接连出手，第三方充电物联网平台有多“香”？ \n",
      " 1 新能源汽车 4.289526462554932 \n",
      " [3.583279609680176, 4.289526462554932, -2.5637705326080322, -1.284340500831604, -2.539374351501465, 0.7272725105285645, 0.6002256274223328, -2.7201085090637207, -0.3425480127334595] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "启动L4级无人卡车研发，阿里加速布局无人物流赛道 \n",
      " 1 新能源汽车 5.910232067108154 \n",
      " [1.5891644954681396, 5.910232067108154, -2.400172472000122, -1.083939552307129, -2.6039886474609375, -0.34220078587532043, -0.04616629704833031, -1.5705159902572632, -0.7511906623840332] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "领克03+Cyan定制版上市：2.0T动力更强 23.68万起售 \n",
      " 1 新能源汽车 7.118701457977295 \n",
      " [1.2653250694274902, 7.118701457977295, -1.9928545951843262, -1.0581796169281006, -2.3823890686035156, 0.14580538868904114, -1.2321372032165527, -2.045470714569092, -1.202070713043213] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "人事变动 | 原长安总裁周治平任一汽集团党委常委、副总经理 \n",
      " 1 新能源汽车 6.007091522216797 \n",
      " [2.2486584186553955, 6.007091522216797, -2.10504412651062, -1.1280585527420044, -2.132216453552246, -0.35430964827537537, -1.1603575944900513, -1.7527345418930054, -0.8249338269233704] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "哈弗大狗上市周年庆 年度宠粉趴半价车豪横大放送 \n",
      " 1 新能源汽车 6.955692291259766 \n",
      " [1.080260992050171, 6.955692291259766, -1.9768035411834717, -1.2219951152801514, -2.489375114440918, 0.40624216198921204, -0.9786412119865417, -1.8701368570327759, -1.3662922382354736] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "奋进“十四五”布局新赛道 2021东风汽车品牌秋季发布会即将举办 \n",
      " 1 新能源汽车 7.121160984039307 \n",
      " [1.0779759883880615, 7.121160984039307, -1.8684048652648926, -1.3709042072296143, -2.150524616241455, -0.14976519346237183, -1.1595277786254883, -1.7961816787719727, -1.2530604600906372] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "2022北京车展将于2022年4月21日开幕 \n",
      " 1 新能源汽车 5.9990973472595215 \n",
      " [1.0429401397705078, 5.9990973472595215, -1.9584181308746338, -1.0270321369171143, -2.104900360107422, 0.012868545949459076, -1.2302398681640625, -1.3262920379638672, -0.9554689526557922] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "三大家电巨头逐鹿智能家居赛道，谁是这条赛道上的领跑者？ \n",
      " 0 ICT 5.317938327789307 \n",
      " [5.317938327789307, 1.2351475954055786, -2.195014715194702, -1.3217324018478394, -2.1048197746276855, 0.33061957359313965, 1.2368320226669312, -2.67098331451416, 0.11408047378063202] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "多“1.0”动力，贵2万，奥迪A7L能月销3000吗？ \n",
      " 1 新能源汽车 6.466500759124756 \n",
      " [1.478200912475586, 6.466500759124756, -2.155521869659424, -1.168621301651001, -2.235391616821289, 0.48448094725608826, -0.7505321502685547, -2.2965097427368164, -1.3229786157608032] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "猪肉股逆势上涨 牧原股份大涨7% 反攻行情开启？ \n",
      " 8 其他 4.859930515289307 \n",
      " [-0.19356966018676758, 0.33648014068603516, -1.6814422607421875, -0.649634599685669, 0.8522780537605286, -0.02013670653104782, -0.7832362651824951, -1.8861100673675537, 4.859930515289307] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "十大券商策略：节前仍是布局窗口 今年A股“第三股风”吹向哪些板块？ \n",
      " 8 其他 4.749872207641602 \n",
      " [-0.053789589554071426, 0.24057282507419586, -1.3514204025268555, -0.9808271527290344, 1.284910798072815, -0.2412574589252472, -1.4169583320617676, -1.6939232349395752, 4.749872207641602] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "三大稀土巨头联手“放大招” 行业格局要变天？ \n",
      " 5 ***** 其他 ***** 原预测: 能源 2.99079966545105 \n",
      " [-0.3300893306732178, 1.9460902214050293, -2.1263725757598877, -1.7865197658538818, 0.5741604566574097, 2.99079966545105, -0.1534302681684494, -2.68733811378479, 1.893126368522644] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "医疗环境中设备的清洁与洗手同样重要 \n",
      " 3 医疗器械 4.019837856292725 \n",
      " [1.9199974536895752, -0.2693465054035187, -1.9051249027252197, 4.019837856292725, -1.4605194330215454, -0.6675017476081848, 0.10018742084503174, -1.9903134107589722, 0.7962245345115662] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "盐湖股份拟1.2亿投建盐湖资源开发中试基地 \n",
      " 1 ***** 其他 ***** 原预测: 新能源汽车 3.0756704807281494 \n",
      " [0.0037838220596313477, 3.0756704807281494, -2.4605729579925537, -1.0502066612243652, -1.2882059812545776, 1.873731255531311, -0.501717209815979, -0.3993108868598938, 0.06010141968727112] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "沈阳新松机器人自动化股份有限公司荣获维科杯·OFweek2021中国工业自动化及数字化行业品牌影响力企业奖 \n",
      " 6 工业机器人 6.034397125244141 \n",
      " [0.2546078562736511, 0.5586656332015991, -1.8082318305969238, -1.0765552520751953, -1.7570701837539673, -1.0342614650726318, 6.034397125244141, -1.9520033597946167, 0.9821884632110596] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "罗克韦尔自动化（中国）有限公司荣获维科杯·OFweek2021中国工业自动化及数字化行业品牌影响力企业奖 \n",
      " 6 工业机器人 3.5031120777130127 \n",
      " [1.6625990867614746, 1.781830906867981, -2.8413867950439453, -1.2616760730743408, -2.480917453765869, 0.07357639819383621, 3.5031120777130127, -2.305629014968872, 1.757363200187683] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "多国推进氢能战略实施 \n",
      " 5 能源 3.520399808883667 \n",
      " [0.2755516469478607, 3.293889284133911, -2.4821507930755615, -1.740010142326355, -0.9644935131072998, 3.520399808883667, -0.8000339865684509, -1.7710649967193604, -0.5419046878814697] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "惠强新材年产3亿㎡襄阳锂电池智能隔膜生产基地试生产 \n",
      " 1 新能源汽车 6.049744129180908 \n",
      " [1.4738030433654785, 6.049744129180908, -2.349447250366211, -1.2456408739089966, -1.6845492124557495, 1.1352828741073608, -0.11335703730583191, -2.415260076522827, -1.2585097551345825] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "上汽发布全新概念车预告图 采用仿生学设计/命名为“鲲” \n",
      " 1 新能源汽车 6.725352764129639 \n",
      " [1.635218858718872, 6.725352764129639, -1.9767591953277588, -1.137627124786377, -2.072627067565918, -0.20570960640907288, -0.9270578622817993, -2.0594687461853027, -1.2647101879119873] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "开启“5G+”赋能新时代，村田重磅亮相ELEXCON2021 \n",
      " 1 新能源汽车 4.451940536499023 \n",
      " [3.324545383453369, 4.451940536499023, -2.8611040115356445, -1.454692006111145, -2.8517675399780273, 0.8630385398864746, 0.7190960049629211, -2.9335861206054688, -0.44741523265838623] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "互联网大会高合丁磊：新造车2.0时代是开放无边界、融合创新的时代 \n",
      " 1 新能源汽车 6.00258207321167 \n",
      " [3.0102920532226562, 6.00258207321167, -2.4293954372406006, -1.4009710550308228, -2.6803793907165527, -0.1913331151008606, -0.3241995871067047, -2.3982093334198, -1.161221981048584] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "吴迎秋：互联网与汽车的融合是新汽车2.0时代关键特征 \n",
      " 1 新能源汽车 6.415212631225586 \n",
      " [2.776937961578369, 6.415212631225586, -2.06489896774292, -1.2857608795166016, -2.459713935852051, -0.2963351011276245, -0.621554434299469, -2.3781819343566895, -1.0789836645126343] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "肖政三：明年6月行业预计能够解决芯片短缺问题 \n",
      " 0 ICT 4.268786907196045 \n",
      " [4.268786907196045, 3.9079174995422363, -2.467087745666504, -1.486337661743164, -1.9517492055892944, -0.044739775359630585, -0.6717008948326111, -2.4937148094177246, -0.16045770049095154] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "加价率最高达4543%！汽车芯片经销商锲特电子被罚50万元 \n",
      " 1 新能源汽车 5.854698181152344 \n",
      " [2.9559335708618164, 5.854698181152344, -1.9665040969848633, -1.0902618169784546, -2.129739284515381, 0.4313996434211731, -1.2096325159072876, -2.366652250289917, -1.3058364391326904] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "不止于全球出行，吉利旗下卫星工厂首台套产品下线 \n",
      " 1 新能源汽车 5.3661603927612305 \n",
      " [3.585592746734619, 5.3661603927612305, -2.7848565578460693, -1.3165040016174316, -2.6322741508483887, 0.3407520353794098, -0.12968306243419647, -2.4603452682495117, -0.494672566652298] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "智己汽车将率先搭载英伟达Orin X芯片 \n",
      " 1 新能源汽车 6.236852169036865 \n",
      " [2.9141502380371094, 6.236852169036865, -1.6994905471801758, -0.9761857390403748, -2.036254405975342, -0.1024438664317131, -1.12032949924469, -2.1278038024902344, -1.213613748550415] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "恒大汽车开跌超12%！消息称其项目已停工：资金严重短缺 \n",
      " 1 新能源汽车 5.764663219451904 \n",
      " [1.632869005203247, 5.764663219451904, -2.41339111328125, -0.7168527245521545, -1.7398167848587036, 0.38362768292427063, -0.9740700721740723, -2.3003504276275635, -0.9792133569717407] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "多款百度合作车型量产上市，Apollo汽车智能化业务优势开始显现 \n",
      " 1 新能源汽车 6.540114879608154 \n",
      " [2.9453513622283936, 6.540114879608154, -2.0523681640625, -1.0660617351531982, -2.4631094932556152, -0.262027770280838, -0.9821962118148804, -2.2863376140594482, -1.1227320432662964] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "更多安全配置 哪吒S亮相2021世界互联网大会 \n",
      " 1 新能源汽车 4.593621253967285 \n",
      " [3.0718295574188232, 4.593621253967285, -2.267381191253662, -1.1268227100372314, -2.738945484161377, 0.20009520649909973, -0.20524846017360687, -2.6211791038513184, -0.6166176795959473] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "禾轩科技年产6万吨电解液材料项目将开工 投资逾亿元 \n",
      " 5 ***** 其他 ***** 原预测: 能源 3.024583101272583 \n",
      " [0.0063414424657821655, 1.9018514156341553, -2.6053688526153564, -1.5124075412750244, -0.23886901140213013, 3.024583101272583, 0.0012634273152798414, -2.5647964477539062, 2.0917723178863525] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "因芯片短缺，奔驰新车交付期或超一年 \n",
      " 1 新能源汽车 5.98555326461792 \n",
      " [3.2760848999023438, 5.98555326461792, -2.0798897743225098, -1.253250241279602, -2.3530216217041016, -0.0974213108420372, -1.0817809104919434, -2.2328622341156006, -1.0153086185455322] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "马斯克：芯片短缺或于明年结束 \n",
      " 1 新能源汽车 4.98590087890625 \n",
      " [3.505660057067871, 4.98590087890625, -2.3416495323181152, -1.1555918455123901, -2.382394313812256, -0.08590283244848251, -0.8012648820877075, -2.088026285171509, -0.7090476751327515] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "马斯克：芯片短缺将在明年结束 \n",
      " 1 新能源汽车 4.801689147949219 \n",
      " [3.533357620239258, 4.801689147949219, -2.488401412963867, -1.2222882509231567, -2.409881591796875, 0.14219877123832703, -0.6871324181556702, -2.1573007106781006, -0.5985232591629028] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "华为公开新专利：用于获取车辆3D信息 \n",
      " 0 ICT 4.766329765319824 \n",
      " [4.766329765319824, 4.555353164672852, -2.3156943321228027, -0.7547720074653625, -2.2813735008239746, -0.8548209071159363, -0.5585492253303528, -2.321474552154541, -0.5976981520652771] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "汽车电商行业新标准确立  奇瑞iCar生态注入互联网基因 \n",
      " 1 新能源汽车 6.532346725463867 \n",
      " [2.70914363861084, 6.532346725463867, -1.89955735206604, -1.3187780380249023, -2.409343719482422, -0.25789234042167664, -1.0045660734176636, -2.2087085247039795, -1.1952717304229736] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "传出收购华晨“中华”品牌后！宝马将在沈阳追加投资250亿元 \n",
      " 1 新能源汽车 6.42455530166626 \n",
      " [1.522958517074585, 6.42455530166626, -2.292936086654663, -1.210518479347229, -2.4141597747802734, 0.3678520619869232, -1.1205414533615112, -2.0173449516296387, -1.0688680410385132] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "意法半导体推出具有内置智能的汽车高端驱动器 可节省高达40%的PCB面积 \n",
      " 1 新能源汽车 4.415570259094238 \n",
      " [4.362489700317383, 4.415570259094238, -2.66584849357605, -1.5163925886154175, -2.364035129547119, -0.6625397205352783, -0.308400422334671, -2.3515114784240723, 0.3633759319782257] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "华为徐直军：部分汽车芯片获得了美国许可 \n",
      " 1 新能源汽车 4.695367336273193 \n",
      " [4.610420227050781, 4.695367336273193, -1.7474024295806885, -1.00970458984375, -2.1864752769470215, -0.4656809866428375, -1.0544930696487427, -2.198167562484741, -0.7308481931686401] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最新预测：全球汽车减产770万辆！不只“缺芯” \n",
      " 1 新能源汽车 5.694221496582031 \n",
      " [2.913033962249756, 5.694221496582031, -2.3443148136138916, -1.2370526790618896, -2.3369503021240234, 0.15826579928398132, -0.7201852202415466, -2.3474762439727783, -1.34355890750885] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "李书福要造手机？官方称目前还没有可以对外披露的消息 \n",
      " 0 ICT 5.105487823486328 \n",
      " [5.105487823486328, 2.2807748317718506, -2.2841765880584717, -0.6192454099655151, -1.5118519067764282, -0.25363683700561523, -0.43622681498527527, -2.181487798690796, 0.3119063377380371] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "首款数字汽车哪吒S亮相2021世界互联网大会 \n",
      " 1 新能源汽车 6.535249710083008 \n",
      " [2.274225950241089, 6.535249710083008, -2.1318774223327637, -1.2210949659347534, -2.4764184951782227, -0.21704727411270142, -0.6654080152511597, -2.1279819011688232, -1.1822892427444458] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "大连打造世界一流铁矿石混配与分拨中心丨钢铁财经资讯速览 \n",
      " 4 钢铁 7.952630996704102 \n",
      " [-1.2332632541656494, -0.21616429090499878, -1.2654035091400146, -1.0714282989501953, 7.952630996704102, -0.39155855774879456, -2.5335450172424316, -0.9073845744132996, 0.19373860955238342] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "能耗双控使钢铁 和有色市场出现调整 \n",
      " 4 钢铁 7.511098384857178 \n",
      " [-0.9216417670249939, -0.11898346245288849, -1.1162059307098389, -1.0720083713531494, 7.511098384857178, -0.4624769687652588, -2.451430320739746, -1.1296346187591553, 0.11113189160823822] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "河北省唐山市应急管理局深入开展钢铁企业重大隐患排查整治 \n",
      " 4 钢铁 7.876492500305176 \n",
      " [-1.1392881870269775, -0.20865502953529358, -1.3185322284698486, -1.0845932960510254, 7.876492500305176, -0.3582821190357208, -2.486992835998535, -0.9026076793670654, 0.26241350173950195] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "中冶北方召开《冶金矿山采矿设计规范》《冶金矿山选矿厂工艺设计规范》修订编制... \n",
      " 8 ***** 其他 ***** 原预测: 其他 3.479205846786499 \n",
      " [-1.3554725646972656, 0.6807985305786133, -2.1283621788024902, -1.0005489587783813, 2.0953898429870605, 0.23087826371192932, -1.3950204849243164, -0.2639540731906891, 3.479205846786499] \n",
      "\n",
      "**model_setup:\n",
      "zeng 0\n",
      "8月份全球64个国家粗钢产量为1.568亿吨，同比下降1.4%丨钢铁财经资讯速览 \n",
      " 4 钢铁 7.7800517082214355 \n",
      " [-1.1894176006317139, -0.45129525661468506, -1.4048526287078857, -1.089315414428711, 7.7800517082214355, -0.2504711151123047, -2.424100637435913, -1.1665103435516357, 0.4499402344226837] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import jieba\n",
    "from train99 import transformers_bert_binary_classification\n",
    "\n",
    "device_s = \"cuda:\" + cuda_num\n",
    "device = torch.device(device_s if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classifier= torch.load(model_save_path,map_location=device)\n",
    "\n",
    "ty = ['ICT', '新能源汽车', '生物医药', '医疗器械', '钢铁', '能源', '工业机器人', '先进轨道交通', '其他']\n",
    "# print(classifier1.predict(\"『巴西』圣保罗城际铁路听证会延期至10月15日\"))  # 0\n",
    "# print(classifier1.predict(\"永恒力叉车入驻京东工业品 载重2吨的叉车设备也能线上采购\"))  # 0\n",
    "\n",
    "def read_list(text_path):\n",
    "    lsit = []\n",
    "    with open('%s' % text_path, 'r', encoding=\"utf8\") as f:  # 打开一个文件只读模式\n",
    "        line = f.readlines()  # 读取文件中的每一行，放入line列表中\n",
    "        for line_list in line:\n",
    "            lsit.append(line_list.replace('\\n', ''))\n",
    "    return lsit\n",
    "\n",
    "\n",
    "def test():\n",
    "    test_list = read_list('test.txt')\n",
    "    for i in test_list:\n",
    "        re = classifier.predict(i)  # 0\n",
    "        result1 = re[1]\n",
    "        result2 = re[0].tolist()\n",
    "\n",
    "        if result2[0][result1] < 3.5:\n",
    "            print(i, '\\n', result1, '***** 其他 ***** 原预测:',ty[result1], result2[0][result1], '\\n', result2[0], '\\n')\n",
    "        else:\n",
    "            print(i, '\\n', result1, ty[result1], result2[0][result1], '\\n', result2[0], '\\n')\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sw0",
   "language": "python",
   "name": "sw0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
